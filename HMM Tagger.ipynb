{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "a5460e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "WORDTAG = 'WORDTAG'\n",
    "GRAM1 = '1-GRAM'\n",
    "GRAM2 = '2-GRAM'\n",
    "GRAM3 = '3-GRAM'\n",
    "RARE = '_RARE_'\n",
    "RARE_THRESHOLD = 5\n",
    "# A I-LOC might be followed by B-LOC if a new location follow one immediately after another one                                                                                                              \n",
    "# There are 9 tags to consider                                                                                                                                                                               \n",
    "TAGS = [\n",
    "    'I-PER',\n",
    "    'I-ORG',\n",
    "    'I-LOC',\n",
    "    'I-MISC',\n",
    "    'B-PER',\n",
    "    'B-ORG',\n",
    "    'B-LOC',\n",
    "    'B-MISC',\n",
    "    'O'\n",
    "]\n",
    "# The start and stop symbols                                                                                                                                                                                 \n",
    "START = '*'\n",
    "STOP = 'STOP'\n",
    "\n",
    "FILL_IN = '_FILL_IN_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "9047be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_counts[(u, v, w)] = count(u, v, w)\n",
    "# q_counts[[u, v]] = count(u, v)\n",
    "# e_counts[(u, x)] = count(u, x)\n",
    "def get_q_e_counts(counts_file_name = 'ner.counts'):\n",
    "    f = open(counts_file_name)\n",
    "\n",
    "    q_counts = defaultdict(int)\n",
    "    e_counts = defaultdict(int)\n",
    "\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\" \")\n",
    "        count = int(parts[0])\n",
    "        if parts[1] == 'WORDTAG':\n",
    "            tag = parts[2]\n",
    "            word = parts[3]\n",
    "            e_counts[(tag, word)] = count\n",
    "            e_counts[tag] = e_counts.get(tag, 0) + count\n",
    "        elif parts[1] == '3-GRAM':\n",
    "            u = parts[2]\n",
    "            v = parts[3]\n",
    "            w = parts[4]\n",
    "            q_counts[(u, v, w)] = count\n",
    "        elif parts[1] == '2-GRAM':\n",
    "            u = parts[2]\n",
    "            v = parts[3]\n",
    "            q_counts[(u, v)] = count\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return q_counts, e_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "id": "c651c76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24780\n"
     ]
    }
   ],
   "source": [
    "e_counts = get_q_e_counts()[1]\n",
    "print(len(e_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "id": "397c5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transforms the data into one involving the rare words                                                                                                                                                 \n",
    "# We then run the count_freqs.py utility to get the new counts across the corpus                                                                                                                             \n",
    "def transform_data(e_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "    Output:\n",
    "        Nothing; write to g\n",
    "    \"\"\"\n",
    "\n",
    "    f = open('ner_train.dat', 'r')\n",
    "    g = open('ner_train_rare.dat', 'w')\n",
    "\n",
    "    # Identify rare words\n",
    "    word_tracker = defaultdict(int)\n",
    "    for key, count in e_counts.items():\n",
    "        if isinstance(key, tuple):\n",
    "            (tag, word) = key\n",
    "            word_tracker[word] += count\n",
    "    \n",
    "    rare_words = {word for word, count in word_tracker.items() if count < RARE_THRESHOLD}\n",
    "\n",
    "    # Read the input file, replace rare words and write to the output file\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) > 1:  # Ensure it's not an empty line\n",
    "            word, tag = parts\n",
    "            if word in rare_words:\n",
    "                g.write(f\"{RARE} {tag}\\n\")\n",
    "            else:\n",
    "                g.write(line)\n",
    "        else:\n",
    "            g.write(\"\\n\")  # Keep sentence boundaries\n",
    "\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653538eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "id": "2a0462e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities e(x_t | y_t)                                                                                                                                                                   \n",
    "def get_emission(y, x, e_counts, x_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y: A tag\n",
    "        x: A word\n",
    "        e_counts: A dictionary with counts(y, x) and counts(y)\n",
    "        x_counts: A dictionary with counts(x)\n",
    "    Output:\n",
    "        The probabilty e(x|y) or e(RARE|y) is x is rare\n",
    "        This is vartheta(x | y) in the lecture\n",
    "    \"\"\"\n",
    "    if y not in e_counts:\n",
    "        return 0\n",
    "    # If a rare word, return e(RARE | y)\n",
    "    if x_counts[x] < RARE_THRESHOLD:\n",
    "        return e_counts[(y, RARE)] / e_counts[y]\n",
    "    # Otherwise, return e(x | y)                                                                                                                                                                             \n",
    "    return e_counts[(y, x)] / e_counts[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "id": "36abd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not that for the baseline decoder we don't need Dynamic Programming\n",
    "# We have max_{y1, ..., YT} = max_{y1}(e(x1|y1))...max_{yT}(e(xT|yT))\n",
    "def baseline_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x, y, log(e(x|y))\" where y is the optimal tag for x\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.baseline_predictions', 'w')\n",
    "\n",
    "    _, e_counts = get_q_e_counts(counts_file_name)\n",
    "    \n",
    "    # Get the counts per word; this is used to get the rare words                                                                                                                                            \n",
    "    # What words need to be replaced with a rare word?\n",
    "    # Note that we do here is take all counts of (u, x) for all u to get the count for x\n",
    "    x_counts = defaultdict(int)\n",
    "    _, e_ori = get_q_e_counts('ner.counts')\n",
    "    for key, count in e_ori.items():\n",
    "        if isinstance(key, tuple):\n",
    "            (tag, word) = key\n",
    "            x_counts[word] += count          \n",
    "\n",
    "    for l in f:\n",
    "        x = l.strip()\n",
    "        if not x:\n",
    "            g.write(\"\\n\")\n",
    "        else:\n",
    "            p_best = -float('inf')\n",
    "            y_best = None\n",
    "            for tag in TAGS:\n",
    "                p = get_emission(tag, x, e_counts, x_counts)\n",
    "                if p > p_best:\n",
    "                    p_best = p\n",
    "                    y_best = tag\n",
    "            g.write('{} {} {}\\n'.format(x, y_best, np.log(p_best)))\n",
    "    f.close()\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "id": "e9014561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the probabilities p(y_t | y_{t-1}, y_{t-2})                                                                                                                                                      \n",
    "def get_transition(y1, y2, y3, q_counts):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        y1: The tag two away from the output tag\n",
    "        y2: The tag right before the output tag\n",
    "        y3: The output tag\n",
    "        q_counts: The counts we need for two or 3 tags being seen together\n",
    "    Output:\n",
    "        q(w | v, u) which is theta(w | v, u) in the lecture\n",
    "    \"\"\"\n",
    "    if (y1, y2) not in q_counts:\n",
    "        return 0\n",
    "    return q_counts.get((y1, y2, y3), 0)/q_counts[(y1, y2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "c2856a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_ner_tagger(\n",
    "        counts_file_name = 'ner_rare.counts'\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        counts_file_name: The counts file we use\n",
    "    Output:\n",
    "        Nothing; write to a new file \"x_t, y_t, log(pi(t, y_{t-1}, y_t))\" where y_t is the optimal tag for x_t\n",
    "        Note that {y_t} is the optimal sequence here, computed by Dynamic Programming\n",
    "    \"\"\"\n",
    "    f = open('ner_dev.dat', 'r')\n",
    "    g = open('ner_dev.hmm_predictions', 'w')\n",
    "\n",
    "    q_counts, e_counts = get_q_e_counts(counts_file_name)\n",
    "\n",
    "    # Get the counts per word; this is used to identify                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "    x_counts = defaultdict(int)\n",
    "    _, e_ori = get_q_e_counts('ner.counts')\n",
    "    for key, count in e_ori.items():\n",
    "        if isinstance(key, tuple):\n",
    "            tag, word = key\n",
    "            x_counts[word] += count\n",
    "\n",
    "    # Can use log probabilities here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "    # Reset all variables                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "    pi = defaultdict(float)\n",
    "    bp = defaultdict(str)\n",
    "    pi[(0, START, START)] = 1.0\n",
    "    T = 0\n",
    "    xT = []\n",
    "    for l in f:\n",
    "        if not l or l == '\\n':\n",
    "            # We have an empty line; if xT has data in it then decode it by working backwords                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "            if xT:\n",
    "                # Define the default values of v and w here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "                pi_max = float('-inf')\n",
    "                v_max = None\n",
    "                w_max = None\n",
    "\n",
    "                # Here we define the tag sequence of v and w\n",
    "                # pi(T, v, w) + np.log(get_transition(v, w, STOP, q)) is what we want to maximize\n",
    "                # We need v and w and from this we need to work back\n",
    "                v_tags = [START] if T == 1 else TAGS\n",
    "                w_tags = TAGS\n",
    "\n",
    "                for v in v_tags:\n",
    "                    for w in w_tags:\n",
    "                        current_value = pi[(T, v, w)] + np.log(get_transition(v, w, STOP, q_counts))\n",
    "                        if current_value > pi_max:\n",
    "                            pi_max = current_value\n",
    "                            v_max = v\n",
    "                            w_max = w\n",
    "                \n",
    "                # Set yT be the sequence [v_max, w_max] if T > 1 and [w_max] otherwise\n",
    "                yT = [v_max, w_max] if T > 1 else [w_max]\n",
    "\n",
    "                \"\"\"\n",
    "                Use backpointers to get the sequence we seek \n",
    "                This is the highest probability tag sequence (y1,..., yT)\n",
    "                Remember we just found v_max and w_max and we have \n",
    "                pi(T, v_max, w_max) = np.log(e(xT | w_max)) + \\max_{u}(q(w_max | v_max, y)*pi(T-1, u, v_max))\n",
    "                We need u, which should be u_max = bp[(T, v_max, w_max)]\n",
    "                We append this to yT to get [u_max, v_max, w_max]\n",
    "                We continue this process on until T = 1 (use a loop)\n",
    "                \"\"\"\n",
    "    \n",
    "                for t in range(T, 2, -1): \n",
    "                    u_max = bp[(t, yT[0], yT[1])]\n",
    "                    yT.insert(0, u_max)\n",
    "                log_pT = []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "                assert(T == len(xT))\n",
    "                assert(len(yT) == len(xT))\n",
    "                \n",
    "                \"\"\"\n",
    "                We want to get the log probability of the sequence\n",
    "                For example, when we are at x1 this is\n",
    "                np.log(q(y1, START, START)) + np.log(e(x1|y1))\n",
    "                \"\"\"\n",
    "                for t in range(len(xT)):\n",
    "                    if t == 0:\n",
    "                        log_pT.append(np.log(get_transition(START, START, yT[t] , q_counts)) + np.log(get_emission(yT[t], xT[t], e_counts, x_counts)))\n",
    "                    elif t == 1:\n",
    "                        log_pT.append(np.log(get_transition(START, yT[t-1], yT[t] , q_counts)) + np.log(get_emission(yT[t], xT[t], e_counts, x_counts)))\n",
    "                    else:\n",
    "                        log_pT.append(np.log(get_transition(yT[t-2], yT[t-1], yT[t] , q_counts)) + np.log(get_emission(yT[t], xT[t], e_counts, x_counts)))\n",
    "                for xt, yt, log_pt in zip(xT, yT, log_pT):\n",
    "                    g.write('{} {} {}\\n'.format(xt, yt, log_pt))\n",
    "                g.write('\\n')\n",
    "\n",
    "\n",
    "            # Reset all variables\n",
    "            # For the next sentence, we'll append words as we see them and compute these \n",
    "            pi = defaultdict(float)\n",
    "            bp = defaultdict(str)\n",
    "            pi[(0, START, START)] = 1.0\n",
    "            T = 0\n",
    "            xT = []\n",
    "        else:\n",
    "            # This is the forward step of Dynamic Programming, where we go from T-1 -> T\n",
    "            l = l.strip().split(' ')\n",
    "            #print(l)\n",
    "            T += 1\n",
    "            xt = l[-1]\n",
    "            xT.append(xt)\n",
    "\n",
    "            # q(w | v, u)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            # What can u be? Consider q(w | v, u) when T = 1 or T = 2 vs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "            u_tags = [START] if T <= 2 else TAGS\n",
    "            # What can v be? Consider q(w | v, u) when T = 1 [Ovs more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "            v_tags = [START] if T == 1 else TAGS\n",
    "            # What can w be? w can only be a true TAG, never START                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "            w_tags = TAGS\n",
    "\n",
    "            \"\"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            For this we use the recursion below:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "            v, w in v_tags, w_tags while u is over u_tags\n",
    "\n",
    "            The probability recursion:\n",
    "            pi(t, v, w) = e(xt | w) max_{u}{q(w | v, u) * pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "\n",
    "            Becomes the log recursion:\n",
    "            pi(t, v, w) = log e(xt | w) + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "\n",
    "            We use logs below to make it easier and avoid overflow                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "            \"\"\"\n",
    "            for v in v_tags:\n",
    "                for w in w_tags:\n",
    "                    # e(x | w); this term is not in the max                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "                    e_temp = np.log(get_emission(w, xt, e_counts, x_counts))\n",
    "\n",
    "                    # pi(t, v, w) = log e(xt | w)  + max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    pi_max = float('-inf')\n",
    "                    u_max = None\n",
    "\n",
    "                    # Do the max with respect to u                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "                    for u in u_tags:\n",
    "                        q_value = np.log(get_transition(u, v, w, q_counts))\n",
    "                        current_value = q_value + e_temp + pi[(T-1, u, v)]\n",
    "                        if current_value > pi_max:\n",
    "                            pi_max = current_value\n",
    "                            u_max = u\n",
    "\n",
    "                    # The arg max of max_{u}{log q(w | v, u)  + pi(t-1, u, v)}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "                    bp[(T, v, w)] = u_max\n",
    "\n",
    "                    # The log probability of ending in (v, w) at time T                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "                    pi[(T, v, w)] = pi_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55db36",
   "metadata": {},
   "source": [
    "# Run code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "id": "853e223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train.dat\n"
     ]
    }
   ],
   "source": [
    "# This gets the number of lines in new_train.dat\n",
    "!wc -l ner_train.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "id": "18e8a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python count_freqs.py ner_train.dat > ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "id": "5613140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 WORDTAG I-ORG EU\n",
      "1 WORDTAG O rejects\n",
      "84 WORDTAG I-MISC German\n",
      "30 WORDTAG O call\n",
      "3382 WORDTAG O to\n",
      "5 WORDTAG O boycott\n",
      "78 WORDTAG I-MISC British\n",
      "3 WORDTAG O lamb\n",
      "7362 WORDTAG O .\n",
      "31 WORDTAG I-PER Peter\n"
     ]
    }
   ],
   "source": [
    "!head ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "id": "1b86887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24968 ner.counts\n"
     ]
    }
   ],
   "source": [
    "!wc -l ner.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "id": "e29b28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # This does the flow of everything, you might want to comment out certain parts                                                                                                                                                                                                       \n",
    "q_counts, e_counts = get_q_e_counts('ner.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "id": "2a2e3783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 1165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_counts['I-ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "id": "ced3632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24780"
      ]
     },
     "execution_count": 1166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "id": "06fdae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18710\n"
     ]
    }
   ],
   "source": [
    "# Get the new data and replace all rare words with _RARE_                                                                                                                                                                                                                             \n",
    "transform_data(e_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "04b0fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  217662 ner_train_rare.dat\n"
     ]
    }
   ],
   "source": [
    "# Should be the same number of lines as above\n",
    "!wc -l ner_train_rare.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81cede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "id": "21a32fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the count_freqs helper again to get the new counts                                                                                                                                                                                                                              \n",
    "# This requires a run outside of this                                                                                                                                                                                                                                                 \n",
    "!python count_freqs.py ner_train_rare.dat > ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "id": "c95796f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5959 ner_rare.counts\n"
     ]
    }
   ],
   "source": [
    "# Many words will get mapped to _RARE_, so it is fairly simple\n",
    "!wc -l ner_rare.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "id": "ccc3f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rare counts for each word\n",
    "# These will allow us to get the new probabilities\n",
    "q_counts, e_counts = get_q_e_counts('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170175e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "id": "e3b57162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline model's performance                                                                                                                                                                                                                                                            \n",
    "baseline_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "id": "53e3019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14043 NEs. Expected 5931 NEs; Correct: 3117.\n",
      "\n",
      "\t precision \trecall \t\tF1-Score\n",
      "Total:\t 0.221961\t0.525544\t0.312106\n",
      "PER:\t 0.435451\t0.231230\t0.302061\n",
      "ORG:\t 0.475936\t0.399103\t0.434146\n",
      "LOC:\t 0.147750\t0.870229\t0.252612\n",
      "MISC:\t 0.491689\t0.610206\t0.544574\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the baseline tagger\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.baseline_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0824ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "id": "96985d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1140-662f97edec31>:129: RuntimeWarning: divide by zero encountered in log\n",
      "  e_temp = np.log(get_emission(w, xt, e_counts, x_counts))\n",
      "<ipython-input-1140-662f97edec31>:137: RuntimeWarning: divide by zero encountered in log\n",
      "  q_value = np.log(get_transition(u, v, w, q_counts))\n",
      "<ipython-input-1140-662f97edec31>:48: RuntimeWarning: divide by zero encountered in log\n",
      "  current_value = pi[(T, v, w)] + np.log(get_transition(v, w, STOP, q_counts))\n"
     ]
    }
   ],
   "source": [
    "# Get HMM model's performance                                                                                                                                                                                                                                                                 \n",
    "hmm_ner_tagger('ner_rare.counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "id": "8323bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4704 NEs. Expected 5931 NEs; Correct: 3649.\n",
      "\n",
      "\t precision \trecall \t\tF1-Score\n",
      "Total:\t 0.775723\t0.615242\t0.686225\n",
      "PER:\t 0.763928\t0.596844\t0.670128\n",
      "ORG:\t 0.611855\t0.478326\t0.536913\n",
      "LOC:\t 0.876458\t0.696292\t0.776056\n",
      "MISC:\t 0.830065\t0.689468\t0.753262\n"
     ]
    }
   ],
   "source": [
    "# This evaluates the HMM tagger; performance should be about double that of the baseline\n",
    "!python eval_ne_tagger.py ner_dev.key ner_dev.hmm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b9a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20305a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a0d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2986a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
